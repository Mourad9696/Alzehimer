{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAww6PK6BfuA"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import numpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "import tensorflow as tf\n",
        "from numpy import asarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "croYBrz50maJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.utils import normalize, to_categorical\n",
        "# import splitfolders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zob20g_fyCWs",
        "outputId": "cf56f3d9-71e3-4754-9360-df5fcd55f280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLNnnyXpxv98",
        "outputId": "68dcc69a-62ea-4501-9da6-f2c38050c664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 6400 files [02:38, 40.51 files/s] \n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio('/content/drive/MyDrive/Dataset', output = '/content/drive/MyDrive/full',\n",
        "                    ratio = (0.8 , 0.0 , 0.2)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Riqf9uzk0rsm"
      },
      "outputs": [],
      "source": [
        "size = 128\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/full/train/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print('\\n')\n",
        "    # print(label)\n",
        "    print('\\n')\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path,cv2.IMREAD_UNCHANGED)\n",
        "        img = cv2.resize(img,(size,size))\n",
        "        train_images.append(img)\n",
        "        train_labels.append(label)\n",
        "        \n",
        "\n",
        "\"\"\"Note: Better to work with (numpy) array than a normal list as in the normal\n",
        "list we will have to iterate over all the elements using a loop\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# print('\\n')\n",
        "# print(\"Train images and Train labels shape: \")\n",
        "# print(\"Shape: \", train_images.shape)\n",
        "# print(\"Shape: \", train_labels.shape)\n",
        "# print('\\n')\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCyVTLyO1pPg"
      },
      "outputs": [],
      "source": [
        "test_images = []\n",
        "test_labels = []\n",
        "for directory_path in glob.glob(\"/content/drive/MyDrive/full/test/*\"):\n",
        "    label = directory_path.split(\"\\\\\")[-1]\n",
        "    print('\\n')\n",
        "    print(label)\n",
        "    print('\\n')\n",
        "    for img_path in glob.glob(os.path.join(directory_path, '*.jpg')):\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path,cv2.IMREAD_UNCHANGED)\n",
        "        img = cv2.resize(img,(size,size))\n",
        "        test_images.append(img)\n",
        "        test_labels.append(label)\n",
        "\n",
        "# print('\\n')\n",
        "#print(\"Test images and Test labels shape: \")\n",
        "#print('\\n')\n",
        "#print('Test Images: ' ,test_images.shape)\n",
        "print(type(test_images))\n",
        "test_images = np.array(test_images, dtype =  object)\n",
        "test_labels = np.array(test_labels)\n",
        "print(type(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vehPtL_y14lm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0df4fa-003a-46d6-c327-0344d31c6501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Here we encoded the labels and the reason behind that is because\n",
        "converting the labels into a numeric form so as to convert them \n",
        "into the machine-readable form will be easier better model and \n",
        "most algorithms cannot handle  the \"Strings\" unless they are \n",
        "converted into a numerical value.\n",
        "'''\n",
        "# print(type(train_labels))\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "test_labels_encoded = le.transform(test_labels)\n",
        "le.fit(train_labels)\n",
        "train_labels_encoded = le.transform(train_labels)\n",
        "print(train_labels_encoded)\n",
        "# print(type(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQYFt6N-187l"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Here we reassingned the variables to new names as they are more meaningful(That is not actual splitting)\n",
        "The splitting was already done\n",
        "'''\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PRDmd0a1-88"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Each number represents a color code. When using the \n",
        "image as it is and passing through a Deep Neural Network,\n",
        "the computation of high numeric values may become more complex.\n",
        "To reduce this we can normalize the values to range from 0 to 1.\n",
        "'''\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jr6DazlALet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b006a13-e75a-4051-a019-ec68d72a8cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5119, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "print(train_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tHiZuzJBrY6"
      },
      "outputs": [],
      "source": [
        "#we could use other activation functions to see the best accuracy\n",
        "activation = 'sigmoid'\n",
        "\n",
        "#sequential(), in keras it is used to arrange Keras layers in sequntial order, until it reaches the output layer\n",
        "feature_extractor = Sequential()\n",
        "'''\n",
        "Conv2D, it is considerd a filter or a kernel used for 2d input data\n",
        "'''\n",
        "feature_extractor.add(Conv2D(32, (3,3), activation = activation, padding = 'same', input_shape = (size, size, 1)))\n",
        "feature_extractor.add(BatchNormalization())\n",
        "\n",
        "feature_extractor.add(Conv2D(32, (3,3), activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
        "\n",
        "'''BatchNormalization(), used in between the  CNN layers,\n",
        "   througth segmenting data into mini_batches so the learning\n",
        "   process would be faster.\n",
        "'''\n",
        "feature_extractor.add(BatchNormalization())\n",
        "feature_extractor.add(MaxPooling2D())\n",
        "\n",
        "feature_extractor.add(Conv2D(64, (3,3), activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
        "feature_extractor.add(BatchNormalization())\n",
        "\n",
        "feature_extractor.add(Conv2D(64, (3,3), activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
        "feature_extractor.add(BatchNormalization())\n",
        "feature_extractor.add(MaxPooling2D())\n",
        "\n",
        "feature_extractor.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffdzmOcQ-Ifb"
      },
      "outputs": [],
      "source": [
        "x = feature_extractor.output  \n",
        "x = Dense(128, activation = activation, kernel_initializer = 'he_uniform')(x)\n",
        "prediction_layer = Dense(4, activation = 'softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUl3Kd-0_tb9",
        "outputId": "1435c07d-c5b7-4cb5-846b-9be0df6144dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_input (InputLayer)   [(None, 128, 128, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 32)      9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8388736   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,455,012\n",
            "Trainable params: 8,454,628\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Make a new model combining both feature extractor and x\n",
        "cnn_model = Model(inputs=feature_extractor.input, outputs=prediction_layer)\n",
        "cnn_model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "print(cnn_model.summary()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIoJNSGh_956",
        "outputId": "58e7a932-6801-40d5-cb95-ecb36da5c6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 519s 3s/step - loss: 1.2101 - accuracy: 0.4733\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 516s 3s/step - loss: 1.0398 - accuracy: 0.5001\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 519s 3s/step - loss: 1.0388 - accuracy: 0.5001\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 514s 3s/step - loss: 1.0390 - accuracy: 0.4989\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 516s 3s/step - loss: 1.0401 - accuracy: 0.4999\n"
          ]
        }
      ],
      "source": [
        "history = cnn_model.fit(x_train, y_train_one_hot, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8spzvWhPAp77"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}